clear, clc%, close all

tau_set = [0.5, 0.6, 0.7, 0.8, 0.9];
fprintf('tau values: %s\n', num2str(tau_set));

% system and network parameters
N_per_tau = 30000;          % symbols per tau
snr = 15;
window_len = 31;
num_feedback_taps = 4;
adaptive_input_len = window_len + num_feedback_taps + 1;
sps = 10; beta = 0.3; span = 6;
h = rcosdesign(beta, span, sps, 'sqrt');

% no need to initialize
X_mega_dataset = [];
Y_mega_dataset = [];

% network architecture
adaptive_df_fnn_layers = [
    featureInputLayer(adaptive_input_len, 'Name', 'Input (Signal+History+Tau)')
    fullyConnectedLayer(128, 'Name', 'Hidden_Layer_1')
    reluLayer('Name', 'Activation_1')
    fullyConnectedLayer(64, 'Name', 'Hidden_Layer_2')
    reluLayer('Name', 'Activation_2')
    fullyConnectedLayer(2, 'Name', 'Output_Scores')
    softmaxLayer('Name', 'Probabilities')
    classificationLayer('Name', 'Loss_and_Output')
];

% data generation loop
fprintf('\nPHASE 2: Generating and Aggregating Data for All Tau Values...\n');

for current_tau = tau_set
    fprintf('  -> Generating %d samples for tau = %.2f...\n', N_per_tau, current_tau);
    
    % signal generation
    bits = randi([0 1], N_per_tau, 1);
    symbols = 1 - 2*bits;
    
    tx_upsampled = upsample(symbols, round(sps*current_tau));
    txSignal = conv(tx_upsampled, h);
    rxSignal = awgn(txSignal, snr, 'measured');
    rxMF = conv(rxSignal, h);

    % --- Data Generation for the current tau ---
    xdata_current_tau = zeros(N_per_tau, adaptive_input_len);
    ydata_current_tau = zeros(N_per_tau, 1);
    total_delay_win = floor(window_len/2);
    
    pulse_delay = (length(h)-1)/2;
    start_idx = 2*pulse_delay + 1;

    for i = (num_feedback_taps + 1):N_per_tau
        ploc = round(start_idx + (i-1)*sps*current_tau);
        if (ploc - total_delay_win > 0) && (ploc + total_delay_win <= length(rxMF))
            current_window = rxMF(ploc - total_delay_win : ploc + total_delay_win);
            past_symbols = symbols(i-1 : -1 : i-num_feedback_taps);
            
            % THE CRUCIAL MODIFICATION: Append the current_tau value
            xdata_current_tau(i, :) = [current_window.', past_symbols.', current_tau];
            ydata_current_tau(i) = bits(i);
        end
    end
    
    % --- Clean up and aggregate ---
    valid_rows = any(xdata_current_tau, 2);
    X_mega_dataset = [X_mega_dataset; xdata_current_tau(valid_rows, :)];
    Y_mega_dataset = [Y_mega_dataset; ydata_current_tau(valid_rows, :)];
end

fprintf('\nTotal training samples generated: %d\n', size(X_mega_dataset, 1));

%% PHASE 3: TRAINING THE ADAPTIVE NETWORK
fprintf('\nPHASE 3: Training the Single Adaptive Network...\n');

% --- Partition the aggregated data ---
Y_categorical = categorical(Y_mega_dataset);
cv = cvpartition(size(X_mega_dataset, 1), 'HoldOut', 0.1); % Use 10% for validation due to large size

X_train = X_mega_dataset(cv.training, :);
Y_train = Y_categorical(cv.training, :);
X_val = X_mega_dataset(cv.test, :);
Y_val = Y_categorical(cv.test, :);

% --- Training Options ---
options = trainingOptions('adam', ...
    'MaxEpochs', 10, ... % Fewer epochs may be needed due to the large dataset
    'MiniBatchSize', 256, ...
    'ValidationData', {X_val, Y_val}, ...
    'ValidationFrequency', 200, ...
    'GradientThreshold', 1, ...
    'Verbose', true, ...
    'Plots', 'training-progress', ...
    'Shuffle', 'every-epoch'); % Shuffle data to ensure network sees mixed taus

% --- Train the Network ---
ftn_detector_adaptive = trainNetwork(X_train, Y_train, adaptive_df_fnn_layers, options);

%% PHASE 4: SAVING THE FINAL GENERALIST MODEL
fprintf('\nPHASE 4: Saving the final, adaptive detector model...\n');
save('final_adaptive_detector.mat', 'ftn_detector_adaptive');
fprintf('Model saved successfully to final_adaptive_detector.mat.\n');